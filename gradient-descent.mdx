---
title: 'Gradient Descent'
description: "Gradiet Descent is an optimization algorithm used to find the values of parameters (coefficients) of a function (f) that minimizes a cost function (cost)."
tags: ['machine-learning', 'optimization','python']
image: 'https://github.com/tiesen243/tiesen243/assets/101703006/0abf567c-2d5f-4947-95ba-465b26ef7bb1'
date: '2024-01-16T18:00:00.000Z'
---


Gradient Descent is an optimization algorithm used to find the values of parameters (coefficients) of a function (f) that minimizes a cost function (cost).

## Gradient Descent Intuition

Gradient Descent is an iterative optimization algorithm to find the minimum of a function. It is a first-order optimization algorithm. This means it only takes into account the first derivative when performing the updates on the parameters.

The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent. This is illustrated in the following figure:

## In python

```python
import numpy as np
import matplotlib.pyplot as plt

def f(x):
    return x**2 + 10*np.sin(x)

def df(x):
    return 2*x + 10*np.cos(x)
    
def gradient_descent(x0, eta, n):
    x = np.zeros(n)
    x[0] = x0
    for i in range(n-1):
        x[i+1] = x[i] - eta*df(x[i])
    return x

x0 = -5
eta = 0.1
n = 50
x = gradient_descent(x0, eta, n)

plt.figure(figsize=(12, 6))
plt.subplot(121)
plt.plot(x, f(x), 'o-')
plt.xlabel('x')
plt.ylabel('f(x)')
plt.subplot(122)
plt.plot(x, df(x), 'o-')
plt.xlabel('x')
plt.ylabel('df(x)')
plt.show()
```


## References

- [Gradient Descent](https://en.wikipedia.org/wiki/Gradient_descent)
